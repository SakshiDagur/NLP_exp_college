{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPH0sVVoA9TAGUfPMciPLMO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SakshiDagur/NLP_exp_college/blob/main/58_Sakshi_Dagur_Expt_08_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**58_Sakshi_Dagur_Exp08**"
      ],
      "metadata": {
        "id": "C8ULMcqGTY6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "3qxA1_k3ThPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample data (context and senses)**bold text**"
      ],
      "metadata": {
        "id": "9rozyiyxTxiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    ([\"The\", \"bank\", \"by\", \"the\", \"river\", \"is\", \"steep.\"], \"financial_institution\"),\n",
        "    ([\"I\", \"walked\", \"along\", \"the\", \"river\", \"bank\", \"yesterday.\"], \"river_bank\"),\n",
        "]"
      ],
      "metadata": {
        "id": "_9MGrWRoT0DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a **vocabulary**"
      ],
      "metadata": {
        "id": "J-pZ1VcwT57E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(word for context, _ in data for word in context)\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}"
      ],
      "metadata": {
        "id": "3br-ZEPzT8-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map sense labels to **integers**"
      ],
      "metadata": {
        "id": "Ge1j25x9T-j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sense_labels = list(set(label for _, label in data))\n",
        "sense_to_idx = {sense: idx for idx, sense in enumerate(sense_labels)}\n",
        "idx_to_sense = {idx: sense for sense, idx in sense_to_idx.items()}"
      ],
      "metadata": {
        "id": "5q_3oDCwUEt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert data to **tensors**"
      ],
      "metadata": {
        "id": "WUEM3IUHUH3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_tensors = [(torch.tensor([word_to_idx[word] for word in context]), torch.tensor(sense_to_idx[sense])) for context, sense in data]\n"
      ],
      "metadata": {
        "id": "r47COLheUJM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the LSTM-based WSD **model**"
      ],
      "metadata": {
        "id": "ij1CavM3UW5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WSDModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, sense_count):\n",
        "        super(WSDModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, sense_count)\n",
        "\n",
        "    def forward(self, context):\n",
        "        embedded = self.embedding(context)\n",
        "        lstm_out, _ = self.lstm(embedded.view(len(context), 1, -1))\n",
        "        prediction = self.fc(lstm_out[-1])\n",
        "        return prediction"
      ],
      "metadata": {
        "id": "w7-v2gNjUZ8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "_ii5jeEeUcXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 64\n",
        "sense_count = len(sense_labels)\n",
        "learning_rate = 0.001\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "sLI_24BsUfvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialize the model**"
      ],
      "metadata": {
        "id": "Ej1K6yMJUlXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = WSDModel(vocab_size, embedding_dim, hidden_dim, sense_count)"
      ],
      "metadata": {
        "id": "-zDFNb-RUof0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the loss function and optimizer**"
      ],
      "metadata": {
        "id": "-QuYcsjyUrbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Fda46TdjUwdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training loop**"
      ],
      "metadata": {
        "id": "jU3nnK-NUxh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, criterion, optimizer, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for context, target_sense in data:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(context)\n",
        "            loss = criterion(output, target_sense.unsqueeze(0))  # Add batch dimension to target\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data)}\")"
      ],
      "metadata": {
        "id": "7YV8vLnDU0DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "n-FkYOLpU9A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, data_tensors, criterion, optimizer, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNccr08-U-mj",
        "outputId": "b269c4c9-858e-4138-abc9-49172001e454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7466766834259033\n",
            "Epoch 2/10, Loss: 0.6383989453315735\n",
            "Epoch 3/10, Loss: 0.554126963019371\n",
            "Epoch 4/10, Loss: 0.48075437545776367\n",
            "Epoch 5/10, Loss: 0.41596630215644836\n",
            "Epoch 6/10, Loss: 0.35845254361629486\n",
            "Epoch 7/10, Loss: 0.3073219880461693\n",
            "Epoch 8/10, Loss: 0.26194437593221664\n",
            "Epoch 9/10, Loss: 0.22186991572380066\n",
            "Epoch 10/10, Loss: 0.1867598071694374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference (predict senses for new contexts)"
      ],
      "metadata": {
        "id": "zf9ZIZ67VBtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    new_context = [\"The\", \"bank\", \"charges\", \"high\", \"fees.\"]\n",
        "    new_context = torch.tensor([word_to_idx.get(word, 0) for word in new_context])\n",
        "    new_context = new_context.unsqueeze(0)  # Add batch dimension\n",
        "    predictions = model(new_context)\n",
        "    predicted_label = idx_to_sense[torch.argmax(predictions).item()]\n",
        "    print(f\"Predicted sense: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nfHfavNVEle",
        "outputId": "908acec6-1716-4c55-fe5d-dff29265aa98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sense: river_bank\n"
          ]
        }
      ]
    }
  ]
}